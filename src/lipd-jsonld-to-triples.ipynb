{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "forced-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import uuid\n",
    "import os\n",
    "import os.path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "smoking-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA = {\n",
    "    'Dataset': {\n",
    "        '@id': ['{dataSetName}'],\n",
    "        '@fromJson': ['addExtraDatasetProperties'],\n",
    "        '@toJson': ['getVariableArchiveTypes'],\n",
    "        'dataSetName': { \n",
    "            'name': 'name', \n",
    "            'alternates': ['paleoArchiveName'] \n",
    "        },\n",
    "        'originalDataURL': { \n",
    "            'name': 'hasLink', \n",
    "            'alternates': ['dataURL'] \n",
    "        },\n",
    "        'dataContributor': {\n",
    "            'name': 'author',\n",
    "            'schema': 'Person',\n",
    "            'alternates': ['whoEnteredinDB', 'MetadataEnteredByWhom'],\n",
    "            'fromJson': 'parsePerson'\n",
    "        },\n",
    "        'archiveType': {\n",
    "            'name': 'proxyArchiveType',\n",
    "            'alternates':[\n",
    "                'archive',\n",
    "                'paleoDataArchive',\n",
    "                'paleoData_Archive'\n",
    "            ]\n",
    "        },\n",
    "        'changelog': {\n",
    "            'name': 'hasChangeLog',\n",
    "            'schema': 'ChangeLog'\n",
    "        },\n",
    "        'investigator': {\n",
    "            'name': 'contributor',\n",
    "            'schema': 'Person',\n",
    "            'multiple': True,\n",
    "            'fromJson': 'parsePersons'\n",
    "        },\n",
    "        'investigators': {\n",
    "            'name': 'contributor',\n",
    "            'schema': 'Person',\n",
    "            'hack': True,\n",
    "            'fromJson': 'parsePersonsString'\n",
    "        },\n",
    "        'funding': { \n",
    "            'name': 'fundedBy', \n",
    "            'multiple': True, \n",
    "            'schema': 'Funding' \n",
    "        },\n",
    "        'pub': { \n",
    "            'name': 'publishedIn', \n",
    "            'multiple': True, \n",
    "            'schema': 'Publication' \n",
    "        },\n",
    "        'geo': {\n",
    "            'name': 'collectedFrom',\n",
    "            'schema': 'Location',\n",
    "            'fromJson': 'parseLocation',\n",
    "            'toJson': 'locationToJson'\n",
    "        },\n",
    "        'paleoData': {\n",
    "            'name': 'includesPaleoData',\n",
    "            'multiple': True,\n",
    "            'schema': 'PaleoData'\n",
    "        },\n",
    "        'chronData': {\n",
    "            'name': 'includesChronData',\n",
    "            'multiple': True,\n",
    "            'schema': 'ChronData'\n",
    "        },\n",
    "        'googleSpreadSheetKey': {\n",
    "            'name': 'hasSpreadsheetLink',\n",
    "            'fromJson': 'getGoogleSpreadsheetURL',\n",
    "            'toJson': 'getGoogleSpreadsheetKey'\n",
    "        },\n",
    "        'dataSetVersion': { \n",
    "            'name': 'datasetVersion' \n",
    "        }\n",
    "    },\n",
    "    'ChangeLog': {\n",
    "        '@id': ['{@parent.@id}', '.ChangeLog.', '{@index}'],\n",
    "        '@category': 'ChangeLog'\n",
    "    },\n",
    "    'Funding': {\n",
    "        '@id': [\n",
    "            '{fundingAgency|agency}',\n",
    "            '.',\n",
    "            '{fundingGrant|grant}'\n",
    "        ],\n",
    "        'agency': { \n",
    "            'name': 'fundingAgency', \n",
    "            'alternates': ['fundingAgency'] \n",
    "        },\n",
    "        'grant': {\n",
    "            'name': 'grantNumber',\n",
    "            'multiple': True,\n",
    "            'alternates': ['fundingGrant']\n",
    "        },\n",
    "        'country': {\n",
    "            'name': 'fundingCountry',\n",
    "            'alternates': ['fundingCountry']\n",
    "        }\n",
    "    },\n",
    "    'Publication': {\n",
    "        '@id': [\n",
    "            'Publication.',\n",
    "            '{identifier.0.id|@parent.dataSetName}',\n",
    "            '{index}'\n",
    "        ],\n",
    "        '@fromJson': ['setIdentifierProperties'],\n",
    "        '@toJson': ['createPublicationIdentifier'],\n",
    "        'title': { \n",
    "            'name': 'title' \n",
    "        },\n",
    "        'year': { \n",
    "            'name': 'publicationYear', \n",
    "            'alternates': ['pubYear'] \n",
    "        },\n",
    "        'citation': { \n",
    "            'name': 'citation', \n",
    "            'type': 'string',\n",
    "            'alternates': ['reference'] \n",
    "        },\n",
    "        'link': { \n",
    "            'name': 'hasLink', \n",
    "            'multiple': True \n",
    "        },\n",
    "        'author': {\n",
    "            'name': 'author',\n",
    "            'schema': 'Person',\n",
    "            'multiple': True,\n",
    "            'fromJson': 'parsePersons'\n",
    "        },\n",
    "        'authors': {\n",
    "            'name': 'author',\n",
    "            'schema': 'Person',\n",
    "            'fromJson': 'parsePersonsString',\n",
    "            'hack': True\n",
    "        }\n",
    "    },\n",
    "    'PaleoData': {\n",
    "        '@id': [\n",
    "            '{@parent.dataSetName}',\n",
    "            '.PaleoData',\n",
    "            '{@index}'\n",
    "        ],\n",
    "        'paleoDataName': { \n",
    "            'name': 'name' \n",
    "        },\n",
    "        'measurementTable': {\n",
    "            'name': 'foundInMeasurementTable',\n",
    "            'multiple': True,\n",
    "            'schema': 'DataTable'\n",
    "        },\n",
    "        'paleoModel': {\n",
    "            'name': 'paleoModeledBy',\n",
    "            'multiple': True,\n",
    "            'schema': 'Model',\n",
    "            'category': 'PaleoModel'\n",
    "        }\n",
    "    },\n",
    "    'ChronData': {\n",
    "        '@id': [\n",
    "            '{@parent.dataSetName}',\n",
    "            '.ChronData',\n",
    "            '{@index}'\n",
    "        ],\n",
    "        'measurementTable': {\n",
    "            'name': 'foundInMeasurementTable',\n",
    "            'multiple': True,\n",
    "            'schema': 'DataTable'\n",
    "        },\n",
    "        'chronModel': {\n",
    "            'name': 'chronModeledBy',\n",
    "            'multiple': True,\n",
    "            'schema': 'Model',\n",
    "            'category': 'ChronModel'\n",
    "        }\n",
    "    },\n",
    "    'Model': {\n",
    "        '@id': ['{@parent.@id}', '.Model', '{@index}'],\n",
    "        'method': { \n",
    "            'name': 'hasCode', \n",
    "            'schema': 'SoftwareCode' \n",
    "        },\n",
    "        'summaryTable': {\n",
    "            'name': 'foundInSummaryTable',\n",
    "            'multiple': True,\n",
    "            'schema': 'DataTable'\n",
    "        },\n",
    "        'ensembleTable': {\n",
    "            'name': 'foundInEnsembleTable',\n",
    "            'multiple': True,\n",
    "            'schema': 'DataTable'\n",
    "        },\n",
    "        'distributionTable': {\n",
    "            'name': 'foundInDistributionTable',\n",
    "            'multiple': True,\n",
    "            'schema': 'DataTable'\n",
    "        }\n",
    "    },\n",
    "    'SoftwareCode': {\n",
    "        '@id': {\n",
    "            '{@parent.@id}',\n",
    "            '.',\n",
    "            '{name|software}'\n",
    "        },\n",
    "        'runCommand': { \n",
    "            'name': 'hasExecutionCommand' \n",
    "        },\n",
    "        'runEnv': { \n",
    "            'name': 'hasExecutionEnvironment' \n",
    "        },\n",
    "        'parameters': { \n",
    "            'type': 'string' \n",
    "        },\n",
    "        'software': { \n",
    "            'name': 'name' \n",
    "        }\n",
    "    },\n",
    "    'DataTable': {\n",
    "        '@id': ['{filename}', '_trunc(4)'],\n",
    "        '@fromJson': ['setInterVariableLinks'],\n",
    "        'filename': { \n",
    "            'name': 'hasFileName', \n",
    "            'type': 'File' \n",
    "        },\n",
    "        'columns': {\n",
    "            'name': 'includesVariable',\n",
    "            'multiple': True,\n",
    "            'schema': 'Variable'\n",
    "        }\n",
    "    },\n",
    "    'Variable': {\n",
    "        '@id': [\n",
    "            '{foundInTable|@parent.@id}',\n",
    "            '.',\n",
    "            '{TSid|tsid}',\n",
    "            '.',\n",
    "            '{variableName|name}'\n",
    "        ],\n",
    "        '@fromJson': [\n",
    "            'setVariableCategory',\n",
    "            'wrapUncertainty',\n",
    "            'createProxySystem',\n",
    "            'addFoundInTable',\n",
    "            'addVariableValues'\n",
    "        ],\n",
    "        '@toJson': [\n",
    "            'setVariableType',\n",
    "            'unwrapUncertainty',\n",
    "            'extractFromProxySystem',\n",
    "            'removeFoundInTable',\n",
    "            'removeDepthProperty'\n",
    "        ],\n",
    "        'number': { \n",
    "            'name': 'hasColumnNumber', \n",
    "            'type': 'integer' \n",
    "        },\n",
    "        'TSid': { \n",
    "            'name': 'hasVariableID', \n",
    "            'alternates': ['tsid'] \n",
    "        },\n",
    "        'variableName': { \n",
    "            'name': 'name' \n",
    "        },\n",
    "        'units': { \n",
    "            'name': 'hasUnits' \n",
    "        },\n",
    "        'measurementMethod': { \n",
    "            'name': 'method' \n",
    "        },\n",
    "        'measurementStandard': { \n",
    "            'name': 'standard' \n",
    "        },\n",
    "        'missingValue': { \n",
    "            'name': 'hasMissingValue' \n",
    "        },\n",
    "        'hasMaxValue': { 'type': 'float' },\n",
    "        'hasMinValue': { 'type': 'float' },\n",
    "        'hasMeanValue': { 'type': 'float' },\n",
    "        'hasMedianValue': { 'type': 'float' },\n",
    "        'instrument': {\n",
    "            'name': 'measuredBy',\n",
    "            'type': 'Individual',\n",
    "            'category': 'Instrument'\n",
    "        },\n",
    "        'calibration': {\n",
    "            'name': 'calibratedVia',\n",
    "            'schema': 'CalibrationModel',\n",
    "            'multiple': True\n",
    "        },\n",
    "        'interpretation': {\n",
    "            'name': 'interpretedAs',\n",
    "            'schema': 'Interpretation',\n",
    "            'category': 'Interpretation',\n",
    "            'multiple': True\n",
    "        },\n",
    "        'hasResolution': {\n",
    "            'alternates': ['resolution'],\n",
    "            'name': 'hasResolution',\n",
    "            'category': 'Resolution',\n",
    "            'schema': 'Resolution',\n",
    "            'alternates': ['hasResolution']\n",
    "        },\n",
    "        'inferredFrom': { \n",
    "            'schema': 'Variable', \n",
    "            'category': 'MeasuredVariable' \n",
    "        },\n",
    "        'hasUncertainty': { \n",
    "            'schema': 'Uncertainty', \n",
    "            'multiple': True \n",
    "        },\n",
    "        'useInGlobalTemperatureAnalysis': { \n",
    "            'name': 'useInPAGES2kGlobalTemperatureAnalysis' \n",
    "        },\n",
    "        'hasValues': {\n",
    "            'type': 'string'\n",
    "        },\n",
    "        'foundInTable': {\n",
    "            'type': 'Individual'\n",
    "        },\n",
    "        'hasProxySystem': {\n",
    "            'type': 'Individual'\n",
    "        },\n",
    "        'takenAtDepth': {\n",
    "            'type': 'Individual'\n",
    "        }\n",
    "    },\n",
    "    'ProxySystemModel': {\n",
    "        '@id': ['{@parent.@id}', '.ProxySystemModel'],\n",
    "        'method': { \n",
    "            'name': 'hasCode', \n",
    "            'schema': 'SoftwareCode' \n",
    "        }\n",
    "    },\n",
    "    'PhysicalSample': {\n",
    "        'hasidentifier': { \n",
    "            'name': 'hasIGSN' \n",
    "        },\n",
    "        'hasname': { \n",
    "            'name': 'name' \n",
    "        },\n",
    "        'housedat': { \n",
    "            'name': 'housedAt' \n",
    "        }\n",
    "    },\n",
    "    'Resolution': {\n",
    "        '@id': ['{@parent.@id}', '.Resolution'],\n",
    "        'hasMaxValue': { 'type': 'float' },\n",
    "        'hasMinValue': { 'type': 'float' },\n",
    "        'hasMeanValue': { 'type': 'float' },\n",
    "        'hasMedianValue': { 'type': 'float' },        \n",
    "        #'@fromJson': ['valuesToString'],\n",
    "        #'@toJson': ['valuesToArray']\n",
    "    },\n",
    "    'Location': {\n",
    "        '@id': ['{@parent.dataSetName}', '.Location'],\n",
    "        'siteName': { \n",
    "            'name': 'name' \n",
    "        },\n",
    "        'coordinates': { \n",
    "            'type': 'Geographic_coordinate' \n",
    "        },\n",
    "        'coordinatesFor': { \n",
    "            'type': 'Individual' \n",
    "        }\n",
    "    },\n",
    "    'Interpretation': {\n",
    "        '@id': [\n",
    "            '{@parent.@id}',\n",
    "            '.Interpretation',\n",
    "            '{@index}'\n",
    "        ],\n",
    "        '@toJson': ['changeSeasonalityType'],\n",
    "        'interpDirection': {\n",
    "            'name': 'interpretationDirection',\n",
    "            'alternates': [\n",
    "                'dir',\n",
    "                'interpDir',\n",
    "                'interpdirection',\n",
    "                'direction'\n",
    "            ]\n",
    "        },\n",
    "        'variable': { \n",
    "            'name': 'name' \n",
    "        },\n",
    "        'variableDetail': { \n",
    "            'name': 'detail', \n",
    "            'alternates': ['variabledetail'] \n",
    "        },\n",
    "        'rank': { 'name': 'hasRank' },\n",
    "        'basis': { 'name': 'relevantQuote' },\n",
    "        'local': { 'name': 'isLocal' }\n",
    "    },\n",
    "    'IsotopeInterpretation': {\n",
    "        '@id': {\n",
    "            '{@parent.@id}',\n",
    "            '.IsotopeInterpretation',\n",
    "            '{@index}'\n",
    "        },\n",
    "        '@fromJson': ['wrapIntegrationTime'],\n",
    "        '@toJson': ['unwrapIntegrationTime'],\n",
    "        'integrationTime': {\n",
    "            'name': 'hasIntegrationTime',\n",
    "            'type': 'Individual',\n",
    "            'schema': 'IntegrationTime'\n",
    "        },\n",
    "        'independentVariable': {\n",
    "            'name': 'hasIndependentVariable',\n",
    "            'schema': 'IndependentVariable',\n",
    "            'multiple': True\n",
    "        }\n",
    "    },\n",
    "    'IntegrationTime': {\n",
    "        '@fromJson': ['wrapUncertainty'],\n",
    "        '@toJson': ['unwrapUncertainty'],\n",
    "        'basis': { \n",
    "            'name': 'relevantQuote' \n",
    "        },\n",
    "        'units': { \n",
    "            'name': 'hasUnits' \n",
    "        },\n",
    "        'independentVariable': {\n",
    "            'name': 'hasIndependentVariable',\n",
    "            'schema': 'IndependentVariable',\n",
    "            'multiple': True\n",
    "        }\n",
    "    },\n",
    "    'IndependentVariable': {\n",
    "        '@id': {\n",
    "            '{@parent.@id}',\n",
    "            '.',\n",
    "            '{name}'\n",
    "        },\n",
    "        'basis': { \n",
    "            'name': 'relevantQuote' \n",
    "        },\n",
    "        'direction': {\n",
    "            'name': 'interpretationDirection',\n",
    "            'alternates': ['dir', 'interpDir', 'interpDirection']\n",
    "        },\n",
    "        'mathematicalRelation': { \n",
    "            'name': 'equation' \n",
    "        },\n",
    "        'rank': { \n",
    "            'name': 'hasRank' \n",
    "        }\n",
    "    },\n",
    "    'CalibrationModel': {\n",
    "        '@id': ['{@parent.@id}', '.Calibration'],\n",
    "        '@fromJson': ['wrapUncertainty'],\n",
    "        '@toJson': ['unwrapUncertainty'],\n",
    "        'reference': { \n",
    "            'name': 'relevantQuote' \n",
    "        }\n",
    "    },\n",
    "    'Person': { '@id': ['{name}'] },\n",
    "    'Uncertainty': {\n",
    "        '@id': {\n",
    "            '{@parent.@id}',\n",
    "            '.Uncertainty',\n",
    "            '{@index}'\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "korean-popularity",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACKLIST = {\n",
    "    'metadataMD5' : 1,\n",
    "    'paleoData_paleoDataMD5' : 1,\n",
    "    'paleoData_paleoMeasurementTableMD5' : 1,\n",
    "    'paleoDataMD5' : 1,\n",
    "    'paleoMeasurementTableMD5' : 1,\n",
    "    'tagMD5' : 1,\n",
    "    'chronData_chronDataMD5' : 1,\n",
    "    'chronData_chronMeasurementTableMD5' : 1,\n",
    "    'chronDataMD5' : 1,\n",
    "    'chronMeasurementTableMD5' : 1,\n",
    "    'earliestSampleDate' : 1,\n",
    "    'latestSampleDate' : 1,\n",
    "    'inCompilation' : 1,\n",
    "    'inCompilationBeta' : 1    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cutting-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONTONS = \"http://linked.earth/ontology#\"\n",
    "NS = \"http://linked.earth/lipd#\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cc08b744",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIPLES = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "synthetic-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ucfirst(s):\n",
    "    return s[0].upper() + s[1:]\n",
    "\n",
    "def lcfirst(s):\n",
    "    return s[0].lower() + s[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "civilian-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addExtraDatasetProperties(obj, objhash) :\n",
    "    _REQUEST = {} # This is not really used here is it ?\n",
    "    for key,value in _REQUEST.items() :\n",
    "        m = re.search(r\"^extra_(.+)\", key)\n",
    "        if m is not None:\n",
    "            prop = m.groups()[0]\n",
    "            if (not (prop in obj)) :\n",
    "                obj[prop] = value\n",
    "    return [obj, objhash, []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "furnished-patrol",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsePersonsString(authstring, parent = None) :\n",
    "    authors = []\n",
    "    if (type(authstring) is list) :\n",
    "        return parsePersons(authstring, None)\n",
    "    \n",
    "    if (re.search(r\"\\s*\\s*\", authstring)) :\n",
    "        auths = re.split(r\"\\s*\\s*\", authstring)\n",
    "        for auth in auths:            \n",
    "            authors.append(parsePerson(auth))\n",
    "        \n",
    "    else : \n",
    "        if (re.search(r\".*,.*,.*\", authstring)) :\n",
    "            auths = re.split(r\"\\s*,\\s*\", authstring)\n",
    "            i = 0\n",
    "            while ( i < len(auths) ) :\n",
    "                name = auths[i]\n",
    "                if not re.search(r\"\\s\", name) :\n",
    "                    i+=1\n",
    "                    name = str(str(auths[i]) + \" \") + str(name)\n",
    "                authors.append({\"name\" : name})\n",
    "                i+=1\n",
    "            \n",
    "        else : \n",
    "            m = re.search(r\"(.+),(.+)\", authstring)\n",
    "            if m is not None:\n",
    "                authors.append({\"name\" : str(str(m.groups()[1]) + \" \") + str(m.groups()[0])})\n",
    "            else : \n",
    "                authors.append({\"name\" : authstring})\n",
    "    return authors\n",
    "\n",
    "\n",
    "def parsePerson(auth, parent = None) :\n",
    "    authname = auth\n",
    "    if (type(auth) is dict) :\n",
    "        authname = auth[\"name\"]\n",
    "    m = re.search(r\"(.+)\\s*,\\s*(.+)\", authname)\n",
    "    if m is not None:\n",
    "        return {\"name\" : str(str(m.groups()[1]) + \" \") + str(m.groups()[0])}\n",
    "    else : \n",
    "        return {\"name\" : authname}\n",
    "\n",
    "    \n",
    "def parsePersons(auths, parent = None) :\n",
    "    authors = []\n",
    "    if (not type(auths) is list) :\n",
    "        return None\n",
    "    \n",
    "    for auth in auths: \n",
    "        authors.append(parsePerson(auth, parent))\n",
    "    return authors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fallen-stadium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseLocation(geo, parent = None) :\n",
    "    ngeo = {}\n",
    "    ngeo[\"locationType\"] = geo[\"type\"] if \"type\" in geo else None\n",
    "    ngeo[\"coordinatesFor\"] = parent[\"@id\"]\n",
    "    coords = geo[\"geometry\"][\"coordinates\"]\n",
    "    if (coords and len(coords) > 0) :\n",
    "        ngeo[\"coordinates\"] = str(str(coords[1]) + \",\") + str(coords[0])\n",
    "        ngeo[\"Wgs84:Lat\"] = coords[1]\n",
    "        ngeo[\"Wgs84:Long\"] = coords[0]\n",
    "        # FIXME: For now assuming points\n",
    "        wkt = str(str(\"POINT(\" + str(coords[1])) + \" \") + str(coords[0])\n",
    "        if (len(coords) > 2) :\n",
    "            ngeo[\"Wgs84:Alt\"] = coords[2]\n",
    "            wkt += \" \" + str(coords[2])\n",
    "        \n",
    "        wkt += \")\"\n",
    "        ngeo[\"Geo:HasGeometry\"] = {\n",
    "            \"@id\" : str(parent[\"@id\"]) + \".Geometry\",\n",
    "            \"@category\" : \"Geo:Geometry\",\n",
    "            \"Geo:AsWKT\" : wkt\n",
    "        }\n",
    "    \n",
    "    if \"properties\" in geo :\n",
    "        for key,value in geo[\"properties\"].items() :\n",
    "            ngeo[key] = value\n",
    "    return ngeo\n",
    "\n",
    "\n",
    "def locationToJson(geo, parent = None) :\n",
    "    geojson = {\n",
    "        \"geometry\":\n",
    "            {\n",
    "                \"coordinates\" : [],\n",
    "                \"properties\" : []\n",
    "            }\n",
    "    }\n",
    "    if \"coordinates\" in geo :\n",
    "        latlong = geo[\"coordinates\"].split(\",\")\n",
    "        geojson[\"geometry\"][\"coordinates\"][0] = float(latlong[1])\n",
    "        geojson[\"geometry\"][\"coordinates\"][1] = float(latlong[0])\n",
    "        geojson[\"geometry\"][\"type\"] = \"Point\"\n",
    "    \n",
    "    if \"wgs84:Long\" in geo :\n",
    "        geojson[\"geometry\"][\"coordinates\"][0] = float(geo[\"wgs84:Long\"])\n",
    "    \n",
    "    if \"wgs84:Lat\" in geo :\n",
    "        geojson[\"geometry\"][\"coordinates\"][1] = float(geo[\"wgs84:Lat\"])\n",
    "    \n",
    "    if \"wgs84:Alt\" in geo :\n",
    "        geojson[\"geometry\"][\"coordinates\"][2] = float(geo[\"wgs84:Alt\"])\n",
    "    \n",
    "    for prop,value in geo.items() :\n",
    "        if prop[0] == \"@\" :\n",
    "            continue\n",
    "        \n",
    "        if prop == \"locationType\" :\n",
    "            geojson[\"type\"] = geo[\"locationType\"]\n",
    "        else : \n",
    "            if prop == \"coordinates\" or prop == \"coordinatesFor\":\n",
    "                # Ignore\n",
    "                pass\n",
    "            else : \n",
    "                if re.search(r\"^(geo|wgs84):\", prop) :\n",
    "                    # Ignore\n",
    "                    pass\n",
    "                else : \n",
    "                    geojson[\"properties\"][prop] = value\n",
    "    \n",
    "    return geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "expired-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUncertainty(val, parent = None) :\n",
    "    uncertainty = {}\n",
    "    uncertainty[\"hasValue\"] = val\n",
    "    uncertainty[\"analytical\"] = val\n",
    "    uncertainty[\"reproducibility\"] = val\n",
    "    return uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "large-surgeon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGoogleSpreadsheetURL(key, parent = None) :\n",
    "    return \"https://docs.google.com/spreadsheets/d/\" + str(key) + \"\"\n",
    "\n",
    "def getGoogleSpreadsheetKey(url:str, parent = None) :\n",
    "    return url.replace(\"https://docs.google.com/spreadsheets/d/\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "billion-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParentProperty(obj, prop) :\n",
    "    parent = obj[\"@parent\"]\n",
    "    while (parent) :\n",
    "        if ((prop in parent)) :\n",
    "            return parent[prop]\n",
    "        \n",
    "        parent = parent[\"@parent\"]\n",
    "    return None\n",
    "\n",
    "def getParentWithPropertyValue(obj, prop, val) :\n",
    "    parent = obj[\"@parent\"]\n",
    "    while (parent) :\n",
    "        if ((prop in parent) and parent[prop] == val) :\n",
    "            return parent\n",
    "        \n",
    "        parent = parent[\"@parent\"]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "harmful-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setIdentifierProperties(pub, objhash) :\n",
    "    props = {}\n",
    "    if \"identifier\" in pub :\n",
    "        for identifier in pub[\"identifier\"] : \n",
    "            if identifier[\"type\"] == \"doi\" :\n",
    "                if \"hasDOI\" not in pub:\n",
    "                    pub[\"hasDOI\"] = []  \n",
    "                pub[\"hasDOI\"].append(identifier[\"id\"])\n",
    "            else : \n",
    "                if identifier[\"type\"] == \"issn\" :\n",
    "                    if \"hasISSN\" not in pub:\n",
    "                        pub[\"hasISSN\"] = []                      \n",
    "                    pub[\"hasISSN\"].append(identifier[\"id\"])\n",
    "                elif identifier[\"type\"] == \"isbn\" :\n",
    "                    if \"hasISBN\" not in pub:\n",
    "                        pub[\"hasISBN\"] = []                          \n",
    "                    pub[\"hasISBN\"].append(identifier[\"id\"])\n",
    "            \n",
    "            if ((\"url\" in identifier)) :\n",
    "                if \"hasLink\" not in pub:\n",
    "                    pub[\"hasLink\"] = []  \n",
    "                pub[\"hasLink\"].append(identifier[\"url\"])\n",
    "\n",
    "        del pub[\"identifier\"]\n",
    "    \n",
    "    return [pub, objhash, []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "environmental-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valuesToString(obj, objhash) :\n",
    "    if \"values\" in obj :\n",
    "        if (type(obj[\"values\"]) is list) :\n",
    "            obj[\"values\"] = \", \".join(obj[\"values\"])\n",
    "    return [obj, objhash, []]\n",
    "\n",
    "def camelCase(id) :\n",
    "    term = \"\"\n",
    "    for subid in re.split(r\"\\s+\", id): \n",
    "        term += ucfirst(subid)\n",
    "    return term\n",
    "\n",
    "def unCamelCase(id) :\n",
    "    regex = r\"(?<=[a-z])(?=[A-Z]) | (?<=[A-Z])(?=[A-Z][a-z])\"\n",
    "    a = re.split(regex, id)\n",
    "    return \" \".join(a).lower()\n",
    "\n",
    "def fromCamelCase(str) :\n",
    "    return ucfirst(str)\n",
    "    #return ucfirst(str.replace(r\"([^A-Z])([A-Z])\"\", \"$1_$2\", str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "monthly-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setVariableCategory(obj, objhash) :\n",
    "    # Default category\n",
    "    obj[\"@category\"] = \"MeasuredVariable\"\n",
    "    obj[\"@schema\"] = \"Variable\"\n",
    "    if ((\"variableType\" in obj)) :\n",
    "        varcat = str(obj[\"variableType\"]) + \"Variable\"\n",
    "        obj[\"@category\"] = ucfirst(varcat)\n",
    "        del obj[\"variableType\"]\n",
    "    else : \n",
    "        if ((\"calibration\" in obj)) :\n",
    "            obj[\"@category\"] = \"InferredVariable\"\n",
    "    return [obj, objhash, []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "valuable-vinyl",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLiPDArchiveType(archiveType) :\n",
    "    return unCamelCase(archiveType)\n",
    "\n",
    "def getArchiveType(id, latitude) :\n",
    "    if not id:\n",
    "        return None\n",
    "    id = id.lower()\n",
    "    if (id == \"tree\") :\n",
    "        return \"Wood\"\n",
    "    else : \n",
    "        if (id == \"bivalve\") :\n",
    "            return \"MolluskShell\"\n",
    "        else : \n",
    "            if (id == \"borehole\") :\n",
    "                if (latitude > 65 or latitude < -65) :\n",
    "                    return \"GlacierIce\"\n",
    "                else : \n",
    "                    return \"Rock\"\n",
    "    return camelCase(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "obvious-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guessSensorType(archive, observation, sensor) :\n",
    "    if (('sensorGenus' in sensor) or ('sensorSpecies' in sensor)) :\n",
    "        if (archive == \"MarineSediment\") :\n",
    "            return \"Foraminifera\"\n",
    "        elif (archive == \"Coral\") :\n",
    "            return \"Polyp\"\n",
    "        elif (archive == \"Wood\") :\n",
    "            return \"Vegetation\"\n",
    "        elif (archive == \"MolluskShell\") :\n",
    "            return \"Bivalves\"\n",
    "        elif (archive == \"Sclerosponge\") :\n",
    "            return \"Sponge\"\n",
    "        return \"OrganicSensor\"\n",
    "    else : \n",
    "        if (archive == \"MarineSediment\" and (observation == \"Uk37\" or observation == \"Alkenone\")) :\n",
    "            type = \"Coccolithophores\"\n",
    "        elif (archive == \"MarineSediment\" and observation == \"TEX86\") :\n",
    "            type = \"Archea\"\n",
    "        elif (archive == \"MarineSediment\" and observation == \"D18O\") :\n",
    "            type = \"Foraminifera\"\n",
    "        elif (archive == \"MarineSediment\" and observation == \"Mg/Ca\") :\n",
    "            type = \"Foraminifera\"\n",
    "        elif (archive == \"LakeSediment\" and (observation == \"Uk37\" or observation == \"Alkenone\")) :\n",
    "            type = \"Coccolithophores\"\n",
    "        elif (archive == \"LakeSediment\" and observation == \"TEX86\") :\n",
    "            type = \"Archea\"\n",
    "        elif (archive == \"LakeSediment\" and observation == \"Midge\") :\n",
    "            type = \"Chironomids\"\n",
    "        elif (archive == \"LakeSediment\" and observation == \"BSi\") :\n",
    "            type = \"Diatoms\"\n",
    "        elif (archive == \"LakeSediment\" and observation == \"Chironomid\") :\n",
    "            type = \"Chironomids\"\n",
    "        elif (archive == \"LakeSediment\" and observation == \"Reflectance\") :\n",
    "            type = \"PhotosyntheticAlgae\"\n",
    "        elif (archive == \"LakeSediment\" and observation == \"Pollen\") :\n",
    "            type = \"Watershed\"\n",
    "        elif (archive == \"Coral\") :\n",
    "            return \"Polyp\"\n",
    "        elif (archive == \"Wood\") :\n",
    "            return \"Vegetation\"\n",
    "        elif (archive == \"MolluskShell\") :\n",
    "            return \"Bivalves\"\n",
    "        elif (archive == \"Sclerosponge\") :\n",
    "            return \"Sponge\"\n",
    "        elif (archive == \"Speleothem\") :\n",
    "            return \"Karst\"\n",
    "        elif (archive == \"GlacierIce\") :\n",
    "            return \"Snow\"\n",
    "        elif (archive == \"LakeSediment\" and observation == \"VarveThickness\") :\n",
    "            return \"Catchment\"\n",
    "        elif (archive == \"GlacierIce\" and observation == \"Melt\") :\n",
    "            return \"IceSurface\"\n",
    "        elif (archive == \"Borehole\") :\n",
    "            return \"Soil\"\n",
    "        else : \n",
    "            return \"InorganicSensor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "wanted-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getObservation(observation) :\n",
    "    if observation is None:\n",
    "        return None\n",
    "    if (observation.lower() == \"alkenone\") :\n",
    "        return \"Uk37\"\n",
    "    return camelCase(observation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "liberal-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVariableId(obj, parentid) :\n",
    "    iobj = dict((k.lower(), v) for k, v in obj.items())\n",
    "    id =  parentid + \".\" + iobj[\"tsid\"]\n",
    "    id += \".\" + str(iobj[\"variablename\"])\n",
    "    return id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "forty-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setInterVariableLinks(obj, objhash) :\n",
    "    depthcol = None\n",
    "    vobjhash = {}\n",
    "    for col in obj[\"columns\"] : \n",
    "        vobjhash[col[\"variableName\"].lower()] = getVariableId(col, obj[\"@id\"])\n",
    "    \n",
    "    depthcol =  vobjhash[\"depth\"] if (\"depth\" in vobjhash) else None\n",
    "    for col in obj[\"columns\"] : \n",
    "        thiscol = getVariableId(col, obj[\"@id\"])\n",
    "        if ((\"inferredFrom\" in col)) :\n",
    "            infcol = col[\"inferredFrom\"].lower()\n",
    "            if ((infcol in vobjhash)) :\n",
    "                col[\"inferredFrom\"] = vobjhash[infcol]\n",
    "            \n",
    "        if (depthcol and thiscol != depthcol) :\n",
    "            col[\"takenAtDepth\"] = depthcol\n",
    "    return [obj, objhash, []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "narrative-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDepthProperty(val, parent = None) :\n",
    "    if ((\"takenAtDepth\" in val)) :\n",
    "        del val[\"takenAtDepth\"]\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "skilled-advertiser",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createProxySystem(obj, hash) :\n",
    "    varid = obj[\"@id\"]\n",
    "    # Deal with proxies\n",
    "    proxyobs = None\n",
    "    sampleid = None\n",
    "    if (\"proxy\" in obj) :\n",
    "        proxyobs = obj[\"proxy\"]\n",
    "        del obj[\"proxy\"]\n",
    "    elif (\"OnProxyObservationProperty\" in obj) :\n",
    "        proxyobs = obj[\"OnProxyObservationProperty\"]\n",
    "        del obj[\"OnProxyObservationProperty\"]\n",
    "    elif (\"ProxyObservationType\" in obj) :\n",
    "        proxyobs = obj[\"ProxyObservationType\"]\n",
    "    \n",
    "    vartype = obj[\"@category\"]\n",
    "    if (vartype and vartype == \"MeasuredVariable\") :\n",
    "        # Get the archive type\n",
    "        dsname = getParentProperty(obj, \"dataSetName\")\n",
    "        geo = getParentProperty(obj, \"geo\")\n",
    "        latitude = 0\n",
    "        if ((\"geometry\" in geo) and len(geo[\"geometry\"][\"coordinates\"]) > 1) :\n",
    "            latitude = geo[\"geometry\"][\"coordinates\"][1]\n",
    "        \n",
    "        archivetype = getParentProperty(obj, \"archiveType\")\n",
    "        if (not archivetype) :\n",
    "            archivetype = getParentProperty(obj, \"archive\")\n",
    "        \n",
    "        archivetype = getArchiveType(archivetype, latitude)\n",
    "        # Create sample (archive)\n",
    "        if (not (\"physicalSample\" in obj)) :\n",
    "            cname = getParentProperty(obj, \"collectionName\")\n",
    "            if (cname) :\n",
    "                obj[\"physicalSample\"] = {\"name\" : cname}\n",
    "            \n",
    "        \n",
    "        if ((\"physicalSample\" in obj)) :\n",
    "            sample = obj[\"physicalSample\"]\n",
    "            sampleid =  sample[\"hasname\"] if (\"hasname\" in sample) else sample[\"name\"]\n",
    "            if ((\"hasidentifier\" in sample)) :\n",
    "                sampleid += \".\" + str(sample[\"hasidentifier\"])\n",
    "            else : \n",
    "                if ((\"identifier\" in sample)) :\n",
    "                    sampleid += \".\" + str(sample[\"identifier\"])\n",
    "            if (not (sampleid in hash)) :\n",
    "                sampleobj = {\n",
    "                    \"@id\" : sampleid, \n",
    "                    \"@category\" : \"PhysicalSample\", \n",
    "                    \"@extracats\" : [archivetype]\n",
    "                }\n",
    "                for pkey,pval in sample.items() :\n",
    "                    sampleobj[pkey] = pval\n",
    "\n",
    "                hash[sampleid] = sampleobj\n",
    "            del obj[\"physicalSample\"]\n",
    "        \n",
    "        observationid = getObservation(proxyobs)\n",
    "        #obj[\"proxy\"])\n",
    "        # Create sensor\n",
    "        sensorid = (str(observationid) if observationid is not None else \"\") + \"DefaultSensor\"\n",
    "        sensor = {\n",
    "            \"@id\" : sensorid, \n",
    "            \"@category\" : \"Sensor\"\n",
    "        }\n",
    "        if ((\"archiveGenus\" in obj)) :\n",
    "            sensor[\"sensorGenus\"] = obj[\"archiveGenus\"]\n",
    "            sensorid = ucfirst(sensor[\"sensorGenus\"].lower())\n",
    "            del obj[\"archiveGenus\"]\n",
    "            if ((\"archiveSpecies\" in obj)) :\n",
    "                sensor[\"sensorSpecies\"] = obj[\"archiveSpecies\"]\n",
    "                sensorid += \" \" + sensor[\"sensorSpecies\"].lower()\n",
    "                del obj[\"archiveSpecies\"]\n",
    "            \n",
    "        \n",
    "        if ((\"sensorGenus\" in obj)) :\n",
    "            sensor[\"sensorGenus\"] = obj[\"sensorGenus\"]\n",
    "            sensorid = ucfirst(sensor[\"sensorGenus\"].lower())\n",
    "            del obj[\"sensorGenus\"]\n",
    "            if ((\"sensorSpecies\" in obj)) :\n",
    "                sensor[\"sensorSpecies\"] = obj[\"sensorSpecies\"]\n",
    "                sensorid += \" \" + sensor[\"sensorSpecies\"].lower()\n",
    "                del obj[\"sensorSpecies\"]\n",
    "            \n",
    "        \n",
    "        if (not (sensorid in hash)) :\n",
    "            sensor[\"@id\"] = sensorid\n",
    "            sensor[\"@category\"] = guessSensorType(archivetype, observationid, sensor)\n",
    "            hash[sensorid] = sensor\n",
    "        \n",
    "        #$hash[$sampleid][\"ProxySensorType\"] = $sensorid\n",
    "        # Create a proxy\n",
    "        #$proxyid = $obj[\"@id\"].\".$archivetype.$sensorid.ProxySystem\"\n",
    "        proxyid = \"ProxySystem.\" + str(archivetype)\n",
    "        if (sensorid) :\n",
    "            proxyid += \".\" + str(sensorid) + \"\"\n",
    "        \n",
    "        if (observationid) :\n",
    "            proxyid += \".\" + str(observationid) + \"\"\n",
    "        \n",
    "        # TODO: $proxyid .= \".$chronmodel\"\n",
    "        # TODO: $proxyid .= \".$paleomodel\"\n",
    "        if (not (proxyid in hash)) :\n",
    "            proxy = {\n",
    "                \"@id\" : proxyid, \n",
    "                \"@category\" : \"ProxySystem\", \n",
    "                \"ProxySensorType\" : sensorid,\n",
    "                \"ProxyArchiveType\" : archivetype,\n",
    "                \"ProxyObservationType\" : observationid\n",
    "            }\n",
    "            if ((\"proxySystemModel\" in obj)) :\n",
    "                proxymodelid = \"\" + str(proxyid) + \".Model\"\n",
    "                # TODO: Create proxy sensor/archive/observation models\n",
    "                proxy = {\n",
    "                    \"@id\" : proxymodelid, \n",
    "                    \"@category\" : \"ProxySystemModel\", \n",
    "                    \"name\" : observationid,\n",
    "                    \"hasProxySensorModel\" : \"\" + str(sensorid) + \".Model\",\n",
    "                    \"hasProxyArchiveModel\" : \"\" + str(archivetype) + \".Model\",\n",
    "                    \"hasProxyObservationModel\" : \"\" + str(observationid) + \".Model\"\n",
    "                }\n",
    "                proxy[\"modeledBy\"] = proxymodelid\n",
    "                hash[proxymodelid] = proxymodel\n",
    "                del obj[\"proxySystemModel\"]\n",
    "            hash[proxyid] = proxy\n",
    "        \n",
    "        obj[\"measuredOn\"] = sampleid\n",
    "        obj[\"ProxyObservationType\"] = observationid\n",
    "        obj[\"hasProxySystem\"] = proxyid\n",
    "        if \"proxy\" in obj:\n",
    "            del obj[\"proxy\"]\n",
    "        return [obj, hash, [sampleid, proxyid, sensorid]]\n",
    "    \n",
    "    return [obj, hash, []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "better-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapIntegrationTime(obj, objhash) :\n",
    "    objid = obj[\"@id\"]\n",
    "    # Deal with integrationTime\n",
    "    pvals = {}\n",
    "    for key,value in obj.items() :\n",
    "        if (re.search(r\"^integrationTime\\$\", key, re.IGNORECASE)) :\n",
    "            pvals[\"hasValue\"] = value\n",
    "            del obj[key]\n",
    "        else:\n",
    "            m = re.search(r\"^integrationTime(.+)\", key)\n",
    "            if m is not None:\n",
    "                nkey = m.groups()[0]\n",
    "                nkey_lcfirst = lcfirst(nkey)\n",
    "                pvals[nkey_lcfirst] = value\n",
    "                del obj[key]\n",
    "\n",
    "    if len(pvals.values()) > 0:\n",
    "        intimeid = objid + '.IntegrationTime'\n",
    "        obj['integrationTime'] = intimeid\n",
    "        intime = {}\n",
    "        intime['@id'] = intimeid\n",
    "        intime['@category'] = 'IntegrationTime'\n",
    "        intime['@schema'] = 'IntegrationTime'\n",
    "        intime.update(pvals)\n",
    "        objhash[intimeid] = intime\n",
    "        return [obj, objhash, [intimeid]]\n",
    "    \n",
    "    return [obj, objhash, []]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "informative-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapUncertainty(obj, objhash) :\n",
    "    objid = obj[\"@id\"]\n",
    "    # Deal with uncertainty\n",
    "    pvals = {}\n",
    "    keys_to_be_deleted = []\n",
    "    for key,value in obj.items() :\n",
    "        if (re.search(r\"^uncertainty\\$\", key, re.IGNORECASE)) :\n",
    "            pvals[\"hasValue\"] = value\n",
    "            keys_to_be_deleted.append(key)\n",
    "        elif (re.search(r\"^uncertainty\", key, re.IGNORECASE)) :\n",
    "            pvals[key] = value\n",
    "            keys_to_be_deleted.append(key)\n",
    "\n",
    "    for key in keys_to_be_deleted:\n",
    "        del obj[key]\n",
    "\n",
    "    if len(pvals.values()) > 0 :\n",
    "        uncid = \"\" + str(objid) + \".Uncertainty\"\n",
    "        obj[\"hasUncertainty\"] = uncid\n",
    "        uncertainty = {\n",
    "            \"@id\": uncid,\n",
    "            \"@category\": \"Uncertainty\"\n",
    "        }\n",
    "        for prop,value in pvals.items() :\n",
    "            uncertainty[prop] = value\n",
    "        \n",
    "        objhash[uncid] = uncertainty\n",
    "        return [obj, objhash, [uncid]]\n",
    "    \n",
    "    return [obj, objhash, []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "civil-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addFoundInTable(obj, objhash) :\n",
    "    obj[\"foundInTable\"] = obj[\"@parent\"][\"@id\"]\n",
    "    return [obj, objhash, []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4f01557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unroll the list to a rdf first/rest structure\n",
    "def unrollValuesListToRDF(lst: list, dtype):\n",
    "    bnodeid = \"_:values\" + uniqid()\n",
    "    rdfns = \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n",
    "    xsdns = \"http://www.w3.org/2001/XMLSchema#\"\n",
    "    TRIPLES.append([\n",
    "        bnodeid,\n",
    "        f\"<{rdfns}type>\",\n",
    "        f\"<{rdfns}Seq>\"\n",
    "    ])\n",
    "    for idx, item in enumerate(lst):\n",
    "        TRIPLES.append([\n",
    "            bnodeid,\n",
    "            f\"<{rdfns}_{idx+1}>\",\n",
    "            f\"\\\"{item}\\\"^^<{xsdns}{dtype}>\"\n",
    "        ])\n",
    "    return bnodeid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ed44079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIPD_CSVS = {}\n",
    "def addVariableValues(obj, objhash) :\n",
    "    csvname = obj[\"@parent\"][\"@id\"] + \".csv\"\n",
    "    colnum = int(obj[\"number\"]) - 1\n",
    "    if csvname in LIPD_CSVS:\n",
    "        df = LIPD_CSVS[csvname]\n",
    "        col = df[colnum]\n",
    "        values = col.tolist()\n",
    "        dtype = \"float\" if col.dtypes == \"float64\" else \"string\"\n",
    "        # TODO: Dumping to json string for now. \n",
    "        # rdf:Seq doesn't seem to be importing well in GraphDB\n",
    "        obj[\"hasValues\"] = json.dumps(values)\n",
    "        #bnodeid = unrollValuesListToRDF(values, dtype)\n",
    "        #obj[\"hasValues\"] = bnodeid\n",
    "        return [obj, objhash, []]\n",
    "    return [obj, objhash, []]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-residence",
   "metadata": {},
   "source": [
    "### Object json reverse conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "nearby-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeFoundInTable(var, parent = None) :\n",
    "    if ((\"foundInTable\" in var)) :\n",
    "        del var[\"foundInTable\"]\n",
    "    return var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-mediterranean",
   "metadata": {},
   "source": [
    "### Testing Lipd Json to Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "under-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expandSchema() :\n",
    "    xschema = {}\n",
    "    for key,props in SCHEMA.items() :\n",
    "        # Add core schema too\n",
    "        corekey = str(key) + str(\"_\" + str(WGCORE) + \"\")\n",
    "        xschema[key] = props\n",
    "        xschema[corekey] = props\n",
    "        for lipdkey,pdetails in props.items() :\n",
    "            if not type(pdetails) is dict:\n",
    "                continue\n",
    "            \n",
    "            if ((\"alternates\" in pdetails)) :\n",
    "                for altkey in pdetails[\"alternates\"]: \n",
    "                    xschema[key][altkey] = pdetails\n",
    "                    xschema[corekey][altkey] = pdetails\n",
    "    SCHEMA = xschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "provincial-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modifyStructureIfNeeded(obj, objhash, schema) :\n",
    "    if ((\"@fromJson\" in schema)) :\n",
    "        for func in schema[\"@fromJson\"]: \n",
    "            (obj, objhash, newids) = globals()[func](obj, objhash)\n",
    "            for newid in newids : \n",
    "                if ((newid in objhash)) :\n",
    "                    newobj = objhash[newid]\n",
    "                    if (type(newobj) is dict) and (\"@category\" in newobj) :\n",
    "                        newschid = newobj[\"@category\"]\n",
    "                        newschema =  SCHEMA[newschid] if (newschid in SCHEMA) else {}\n",
    "                        (objhash[newid], objhash) = modifyStructureIfNeeded(newobj, objhash, newschema)\n",
    "    \n",
    "    return [obj, objhash]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "comprehensive-direction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math, random\n",
    "\n",
    "def uniqid(prefix='', more_entropy=False):\n",
    "    m = time.time()\n",
    "    sec = math.floor(m)\n",
    "    usec = math.floor(1000000 * (m - sec))\n",
    "    if more_entropy:\n",
    "        lcg = random.random()\n",
    "        the_uniqid = \"%08x%05x%.8F\" % (sec, usec, lcg * 10)\n",
    "    else:\n",
    "        the_uniqid = '%8x%05x' % (sec, usec)\n",
    "\n",
    "    the_uniqid = (prefix if prefix else '') + the_uniqid\n",
    "    return the_uniqid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eleven-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCompoundKeyId(compound_key, obj) :\n",
    "    tobj = obj\n",
    "    for key in compound_key : \n",
    "        if ((type(tobj) is dict) and (key in tobj)) :\n",
    "            tobj = tobj[key]\n",
    "        else : \n",
    "            return None\n",
    "        \n",
    "    if not type(tobj) is dict:\n",
    "        return tobj\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "hearing-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBindingKeyId(key, obj) :\n",
    "    key_options = key.split(\"|\")\n",
    "    for optkey in key_options : \n",
    "        compound_key = optkey.split(\".\")\n",
    "        keyid = getCompoundKeyId(compound_key, obj)\n",
    "        if (keyid) :\n",
    "            return keyid\n",
    "    return uniqid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "authorized-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFunctionKeyId(fn, arg, curobjid) :\n",
    "    if (fn == \"trunc\") :\n",
    "        return curobjid[0:0 + len(curobjid) - int(arg)]\n",
    "    elif (fn == \"uniqid\") :\n",
    "        return str(curobjid) + uniqid(arg)\n",
    "    return curobjid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "outer-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createIdFromPattern(pattern, obj) :\n",
    "    objid = \"\"\n",
    "    for key in pattern : \n",
    "        m = re.search(r\"{(.+)}\", key)\n",
    "        if m and len(m.groups()) > 0 :\n",
    "            objid += str(getBindingKeyId(m.groups()[0], obj))\n",
    "        else : \n",
    "            m = re.search(r\"_(.+)\\((.*)\\)\", key)\n",
    "            if m and len(m.groups()) > 1:\n",
    "                fn = m.groups()[0]\n",
    "                arg = m.groups()[1]\n",
    "                objid = str(getFunctionKeyId(fn, arg, objid))\n",
    "            else : \n",
    "                objid += str(key)\n",
    "    return objid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "continent-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixTitle(titleid) :\n",
    "    return titleid.replace(r\"@\\\\x{FFFD}@u\", '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "foster-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getObjectId(obj, category, schema) :\n",
    "    if type(obj) is dict:\n",
    "        objid =  \"Unknown.\" + uniqid(category)\n",
    "    else:\n",
    "        objid = ucfirst(obj).replace(\" \", \"_\")\n",
    "    if ((\"@id\" in schema)) :\n",
    "        objid = createIdFromPattern(schema[\"@id\"], obj)\n",
    "    \n",
    "    return fixTitle(objid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "comic-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapLipdJson(obj, parent, index, category, schemaname, hash) :\n",
    "    schema =  SCHEMA[schemaname] if (schemaname in SCHEMA) else {}\n",
    "    SCHEMA[schemaname] = schema\n",
    "    \n",
    "    if not type(obj) is dict:\n",
    "        return obj\n",
    "    \n",
    "    obj[\"@parent\"] = parent\n",
    "    obj[\"@index\"] = index\n",
    "    obj[\"@schema\"] = schemaname\n",
    "    \n",
    "    objid = getObjectId(obj, category, schema)\n",
    "    if ((\"@id\" in obj)) :\n",
    "        objid = obj[\"@id\"]\n",
    "    if ((objid in hash)) :\n",
    "        return objid\n",
    "    obj[\"@id\"] = objid\n",
    "    \n",
    "    (obj, hash) = modifyStructureIfNeeded(obj, hash, schema)\n",
    "    \n",
    "    if (\"@category\" in obj) :\n",
    "        category = obj[\"@category\"]\n",
    "    hash[objid] = {\n",
    "        \"@id\": objid,\n",
    "        \"@category\" : category,\n",
    "        \"@schema\" : schemaname\n",
    "    }\n",
    "    item = hash[objid]\n",
    "    \n",
    "    if type(obj) is dict :\n",
    "        for propkey,value in obj.items() :\n",
    "            if (propkey[0] == \"@\") :\n",
    "                continue\n",
    "            \n",
    "            if propkey in BLACKLIST :\n",
    "                continue\n",
    "            \n",
    "            details = {}\n",
    "            pname = propkey\n",
    "            if propkey in schema :\n",
    "                details = schema[propkey]\n",
    "                pname =  details[\"name\"] if (\"name\" in details) else propkey\n",
    "            \n",
    "            dtype =  details[\"type\"] if (\"type\" in details) else None\n",
    "            cat =  details[\"category\"] if (\"category\" in details) else None\n",
    "            sch =  details[\"schema\"] if (\"schema\" in details) else None\n",
    "            fromJson =  details[\"fromJson\"] if (\"fromJson\" in details) else None\n",
    "            subobject =  details[\"subobject\"] if (\"subobject\" in details) else False\n",
    "            if (sch and not cat) :\n",
    "                cat = sch\n",
    "            if (fromJson) :\n",
    "                value = globals()[fromJson](value, obj)\n",
    "                if (not value) :\n",
    "                    continue\n",
    "                \n",
    "                if (pname) :\n",
    "                    if (type(value) is list) :\n",
    "                        index = 1\n",
    "                        for subvalue in value: \n",
    "                            if (type(value) is dict):\n",
    "                                if propkey not in item:\n",
    "                                    item[propkey] = []\n",
    "                                item[propkey].append(mapLipdJson(subvalue, obj, index, cat, sch, hash))\n",
    "                                index+=1\n",
    "                    else : \n",
    "                        if (type(value) is dict):\n",
    "                            item[propkey] = mapLipdJson(value, obj, None, cat, sch, hash)\n",
    "                        else : \n",
    "                            item[propkey] = value\n",
    "                        \n",
    "                    \n",
    "                else : \n",
    "                    if (type(value) is dict):\n",
    "                        for subpropkey,subvalue in value.items() :\n",
    "                            item[subpropkey] = subvalue\n",
    "                continue\n",
    "            \n",
    "            if (not pname) :\n",
    "                continue\n",
    "            \n",
    "            if (subobject) :\n",
    "                if \"@subobjects\" not in item:\n",
    "                    item[\"@subobjects\"] = []\n",
    "                item[\"@subobjects\"].append({ prop : value })\n",
    "                continue\n",
    "            \n",
    "            if (type(value) is list):\n",
    "                index = 1\n",
    "                for subvalue in value: \n",
    "                    if propkey not in item:\n",
    "                        item[propkey] = []                    \n",
    "                    item[propkey].append(mapLipdJson(subvalue, obj, index, cat, sch, hash))\n",
    "                    index+=1\n",
    "                \n",
    "            else : \n",
    "                if (type(value) is dict):\n",
    "                    if propkey not in item:\n",
    "                        item[propkey] = []                      \n",
    "                    item[propkey].append(mapLipdJson(value, obj, None, cat, sch, hash))\n",
    "                else : \n",
    "                    if (dtype == \"Individual\") :\n",
    "                        item[propkey] = value\n",
    "                        if (not (value in hash)) :\n",
    "                            hash[value] = {\n",
    "                                \"@id\" : value,\n",
    "                                \"@category\" : cat,\n",
    "                                \"@schema\" : sch\n",
    "                            }\n",
    "                    else : \n",
    "                        item[propkey] = value\n",
    "\n",
    "    hash[objid] = item\n",
    "    return objid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "elder-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guessDataValueType(val) :\n",
    "    value = str(val)\n",
    "    if (re.search(r\"^-?\\d+$\", value)) :\n",
    "        return \"float\" #\"integer\"\n",
    "    \n",
    "    if (re.search(r\"^-?\\d+\\.\\d+$\", value)) :\n",
    "        return \"float\"\n",
    "    \n",
    "    if (re.search(r\"^[2][0-9]{3}[-][0-1][0-9][-][0-3][0-9]\", value)) :\n",
    "        return \"date\"\n",
    "    \n",
    "    if (re.search(r\"^(true|false)$\", value, re.IGNORECASE)) :\n",
    "        return \"boolean\"\n",
    "    \n",
    "    if (re.search(r\"^http\", value)) :\n",
    "        return \"url\"\n",
    "    \n",
    "    #if (re.search(r\"^.+@.+\\..+\", value)) :\n",
    "    #    return \"Email\"\n",
    "    \n",
    "    if (re.search(r\"^\\\".+\\\"$\", value)) :\n",
    "        return \"string\"\n",
    "    \n",
    "    if (re.search(r\"^'.+'$\", value)) :\n",
    "        return \"string\"\n",
    "    \n",
    "    return \"string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "classified-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guessValueType(value) :\n",
    "    if value:\n",
    "        if type(value) is list :\n",
    "            for subvalue in value :\n",
    "                return guessValueType(subvalue)\n",
    "        elif type(value) is dict : \n",
    "            return \"Individual\"\n",
    "        \n",
    "        else : \n",
    "            valtype = guessDataValueType(value)\n",
    "            return valtype\n",
    "\n",
    "    return \"string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "legendary-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPropertyDetails(key, schema, value) :\n",
    "    pname = fromCamelCase(key)\n",
    "    details = {\n",
    "        \"name\": pname\n",
    "    }\n",
    "    if (key in schema) and (\"@@processed\" in schema[key]) :\n",
    "        return schema[key]\n",
    "    \n",
    "    # Get details from schema\n",
    "    if (key in schema) :\n",
    "        for skey,svalue in schema[key].items() :\n",
    "            details[skey] = svalue\n",
    "    \n",
    "    if ((\"schema\" in details)) :\n",
    "        details[\"type\"] = \"Individual\"\n",
    "    \n",
    "    pname = ucfirst(details[\"name\"])\n",
    "    \n",
    "    # Get more details from the property definition (if it exists)\n",
    "    \"\"\"\n",
    "    newname = resolveProperty(pname)\n",
    "    if (newname) :\n",
    "        details[\"type\"] = getOntPropertyRange(newname)\n",
    "        details[\"name\"] = newname\n",
    "    \"\"\" \n",
    "    \n",
    "    if (not (\"type\" in details)) :\n",
    "        details[\"type\"] = guessValueType(value)\n",
    "        if (not (\"type\" in details)) :\n",
    "            details[\"type\"] = \"string\"\n",
    "\n",
    "    details[\"@@processed\"] = True\n",
    "    schema[key] = details\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "electric-paint",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitizeId(id):\n",
    "    return re.sub(r\"[^a-zA-Z0-9\\-_\\.]\", \"_\", id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "executed-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual\n",
    "def createIndividual(objid) :\n",
    "    return NS + sanitizeId(objid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "flexible-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class\n",
    "def createClass(category) :\n",
    "    return ONTONS + sanitizeId(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "backed-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create property\n",
    "def createProperty(prop, dtype, cat, icon, multiple) :\n",
    "    return [ ONTONS + lcfirst(sanitizeId(prop)), dtype ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "overall-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set individual classes\n",
    "def setIndividualClasses(objid, category, extracats) :\n",
    "    rdftype = \"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\"\n",
    "    if objid and category:\n",
    "        TRIPLES.append([\n",
    "            \"<\"+objid+\">\",\n",
    "            \"<\"+rdftype+\">\",\n",
    "            \"<\"+category+\">\"\n",
    "        ])\n",
    "    for ecat in extracats:\n",
    "        if objid and ecat:\n",
    "            TRIPLES.append([\n",
    "                \"<\"+objid+\">\",\n",
    "                \"<\"+rdftype+\">\",\n",
    "                \"<\"+createClass(ecat)+\">\"\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "incident-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "def escape( str ):\n",
    "    str = str.replace(\"&\", \"&amp;\")\n",
    "    str = str.replace(\"<\", \"&lt;\")\n",
    "    str = str.replace(\">\", \"&gt;\")\n",
    "    str = str.replace(\"\\\"\", \"\\\\\\\"\")\n",
    "    str = str.replace(\"\\n\", \" \")\n",
    "    str = str.replace(\"\\r\", \" \")\n",
    "    str = re.sub(r\"\\\\$\", \"\", str)\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "secure-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set property value\n",
    "def setProperty( objid, prop, value ):\n",
    "    if (type(value) is list) :\n",
    "        for subvalue in value : \n",
    "            setProperty(objid, prop, subvalue)\n",
    "        return\n",
    "\n",
    "    (propid, dtype) = prop\n",
    "    if objid and value:\n",
    "        if re.search(\"^.*[^a-zA-Z]?nan[^a-zA-Z]?.*$\", str(value).lower()):\n",
    "            return\n",
    "        if re.search(\"^.*[^a-zA-Z]?na[^a-zA-Z]?.*$\", str(value).lower()):\n",
    "            return\n",
    "        \n",
    "        if type(value) is str:\n",
    "            value = escape(value)\n",
    "\n",
    "        if dtype == \"boolean\":\n",
    "            value = str(value).lower()\n",
    "            if value != \"true\":\n",
    "                value = \"false\"\n",
    "        \n",
    "        elif dtype == \"float\":\n",
    "            m = re.search(r\"(\\-?\\d+\\.?\\d*)\", str(value))\n",
    "            if m:\n",
    "                value = m.group(1)\n",
    "            else:\n",
    "                value = 0.0\n",
    "\n",
    "        elif dtype == \"integer\":\n",
    "            m = re.search(r\"(\\-?\\d+)\", str(value))\n",
    "            if m:\n",
    "                value = m.group(1)\n",
    "            else:\n",
    "                value = 0\n",
    "\n",
    "        if dtype == \"Individual\":\n",
    "            value = createIndividual(value)\n",
    "            value = \"<\" + value + \">\"\n",
    "        elif dtype == \"List\":\n",
    "            value = value\n",
    "        else:\n",
    "            value = '\"' + str(value) + '\"' + \"^^<http://www.w3.org/2001/XMLSchema#\" + dtype + \">\"\n",
    "        \n",
    "        TRIPLES.append([\n",
    "            \"<\"+objid+\">\",\n",
    "            \"<\"+propid+\">\",\n",
    "            value\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "thick-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set subobject propvals\n",
    "def setSubobjects(objid, subobjid, subpropvals, schema) :\n",
    "    if (not subpropvals) :\n",
    "        return\n",
    "    \n",
    "    subobjectid = str(objid) + \"_\" + str(subobjid)\n",
    "    for pval in subpropvals : \n",
    "        for key,value in pval.items() :\n",
    "            if (key[0] == \"@\") :\n",
    "                continue\n",
    "            \n",
    "            details = getPropertyDetails(key, schema, value)\n",
    "            prop = details[\"name\"]\n",
    "            type = details[\"type\"]\n",
    "            icon =  details[\"icon\"] if (\"icon\" in details) else None\n",
    "            cat =  details[\"category\"] if (\"category\" in details) else None\n",
    "            sch =  details[\"schema\"] if (\"schema\" in details) else None\n",
    "            fromJson =  details[\"fromJson\"] if (\"fromJson\" in details) else None\n",
    "            multiple =  details[\"multiple\"] if (\"multiple\" in details) else False\n",
    "            # Create & set Property\n",
    "            propDI = createProperty(prop, type, cat, icon, multiple)\n",
    "            setProperty(subobjectid, propDI, value)\n",
    "            #print \"|$key=$value\"\n",
    "\n",
    "    #print \"\\n\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "indie-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createIndividualFull(obj) :\n",
    "    category = obj[\"@category\"]\n",
    "    extracats =  obj[\"@extracats\"] if (\"@extracats\" in obj) else {}\n",
    "    schemaname =  obj[\"@schema\"] if (\"@schema\" in obj) else category\n",
    "    schema =  SCHEMA[schemaname] if (schemaname in SCHEMA) else {}\n",
    "    objid = obj[\"@id\"]\n",
    "    if (not objid) :\n",
    "        return\n",
    "    \n",
    "    subobjects = {}\n",
    "    # Create category\n",
    "    if (category) :\n",
    "        category = createClass(category)\n",
    "    \n",
    "    objid = createIndividual(objid)\n",
    "    \n",
    "    # Set Individual classes\n",
    "    setIndividualClasses(objid, category, extracats)\n",
    "    \n",
    "    for key,value in obj.items() :\n",
    "        if (key[0] == \"@\") :\n",
    "            continue\n",
    "        \n",
    "        details = getPropertyDetails(key, schema, value)\n",
    "        prop = details[\"name\"]\n",
    "        dtype = details[\"type\"]\n",
    "        icon =  details[\"icon\"] if (\"icon\" in details) else None\n",
    "        cat =  details[\"category\"] if (\"category\" in details) else None\n",
    "        sch =  details[\"schema\"] if (\"schema\" in details) else None\n",
    "        if (sch and not cat) :\n",
    "            cat = sch\n",
    "        \n",
    "        fromJson =  details[\"fromJson\"] if (\"fromJson\" in details) else None\n",
    "        multiple =  details[\"multiple\"] if (\"multiple\" in details) else False\n",
    "        subobject =  details[\"subobject\"] if (\"subobject\" in details) else False\n",
    "        if (not prop) :\n",
    "            continue\n",
    "        \n",
    "        # Create Property\n",
    "        propDI = createProperty(prop, dtype, cat, icon, multiple)\n",
    "        \n",
    "        # Set property value\n",
    "        if (dtype == \"Individual\" or type(value) is dict) :\n",
    "            setProperty(objid, propDI, value)\n",
    "        else : \n",
    "            if (dtype == \"File\") :\n",
    "                # Enable this ?\n",
    "                \"\"\"\n",
    "                fileid = uploadFile(value)\n",
    "                if (fileid) :\n",
    "                    protectIndividual(fileid)\n",
    "                    data = setProperty(data, propDI, fileid)\n",
    "                \"\"\"\n",
    "\n",
    "            else : \n",
    "                setProperty(objid, propDI, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "violent-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files_with_extension(directory, extension):\n",
    "    myregexobj = re.compile('\\.'+extension+'$')\n",
    "    try: \n",
    "        for entry in os.scandir(directory):\n",
    "            if entry.is_file() and myregexobj.search(entry.path): \n",
    "                yield entry.path, entry.name\n",
    "            elif entry.is_dir():   # if its a directory, then repeat process as a nested function\n",
    "                yield from find_files_with_extension(entry.path, extension)\n",
    "    except OSError as ose:\n",
    "        print('Cannot access ' + directory +'. Probably a permissions error ', ose)\n",
    "    except FileNotFoundError as fnf:\n",
    "        print(directory +' not found ', fnf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "toxic-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIPLES = []\n",
    "def convertLipdJsonToRDF(jsonpath, rdfpath, url):\n",
    "    TRIPLES.clear()    \n",
    "    objhash = {}\n",
    "    \n",
    "    with open(jsonpath) as f:\n",
    "        obj = json.load(f)\n",
    "        obj[\"hasUrl\"] = url\n",
    "    \n",
    "        mapLipdJson(obj, None, None, \"Dataset\", \"Dataset\", objhash)\n",
    "\n",
    "        for key, item in objhash.items():\n",
    "            createIndividualFull(item)\n",
    "\n",
    "        with open(rdfpath, \"w\") as f:\n",
    "            for triple in TRIPLES:\n",
    "                f.write(\" \".join(triple) + \" .\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "recreational-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "lipd_unzip_dir = \"../data/unzipped\"\n",
    "rdfdir = \"../data/rdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "innocent-curve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "jsons = find_files_with_extension(lipd_unzip_dir, 'jsonld')\n",
    "\n",
    "for jsonpath, _ in jsons:\n",
    "    jsondir = os.path.dirname(jsonpath)\n",
    "    csvs = find_files_with_extension(jsondir, 'csv')\n",
    "    LIPD_CSVS = {}\n",
    "    for csvpath, _ in csvs:\n",
    "        csvname = os.path.basename(csvpath)        \n",
    "        LIPD_CSVS[csvname] = pd.read_csv(csvpath, header=None)\n",
    "\n",
    "    lipddir = os.path.dirname(os.path.dirname(jsondir))\n",
    "    lipdname = os.path.basename(lipddir)\n",
    "    catdir = os.path.dirname(lipddir)\n",
    "    catname = os.path.basename(catdir)\n",
    "    rdfcatdir = os.path.join(rdfdir, catname)\n",
    "    if not os.path.exists(rdfcatdir):\n",
    "        os.makedirs(rdfcatdir)\n",
    "    rdfpath = os.path.join(rdfcatdir, lipdname+\".nt\")\n",
    "    url = \"https://data.mint.isi.edu/files/lipd/\" + catname + \"/\" + lipdname\n",
    "\n",
    "    NS = \"http://linked.earth/lipd/\" + catname + \"#\"    \n",
    "    convertLipdJsonToRDF(jsonpath, rdfpath, url)\n",
    "    \n",
    "    print(\".\", flush=True, end='')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-poultry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('env_tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9afaddfd3d29c59bb4b2e75e9a6fe5227128f879b6030105932f5a2ce7763049"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
